{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nl_tp_m2m\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import AdamW, get_scheduler\n",
    "from sacrebleu.metrics import BLEU\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.functional.text.rouge import rouge_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/m2m100_418M\"\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "batch_size = 8\n",
    "learning_rate = 1e-5\n",
    "epoch_num = 5\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'en'\n",
    "train_set_size = 8213 #0.8\n",
    "valid_set_size = 1027 #0.1\n",
    "test_set_size = 1027 #0.1\n",
    "train_path = '/home/xinming/Text2ESQ/input/v2/easy_train.csv'\n",
    "test_path = '/home/xinming/Text2ESQ/input/v2/easy_test.csv'\n",
    "valid_path = '/home/xinming/Text2ESQ/input/v2/easy_valid.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = BLEU()\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, src_lang=src_lang, tgt_lang=tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLTP_Dataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "    \n",
    "    def load_data(self, data_file):\n",
    "        Data = {}\n",
    "        df = pd.read_csv(data_file)\n",
    "        for idx, x in enumerate(df.index):\n",
    "            Data[idx] = {'en': df['tp'][x].strip(), 'zh_en': df['nl'][x], 'vaers_key':x}\n",
    "        return Data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def preprocess(data):\n",
    "    inputs = [x['zh_en'] for x in data]\n",
    "    targets = [x['en'] for x in data]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=max_input_length, truncation=True, padding=True, return_tensors='pt')\n",
    "    \n",
    "    end_token_index = torch.where(model_inputs['labels'] == tokenizer.eos_token_id)[1]\n",
    "    for idx, end_idx in enumerate(end_token_index):\n",
    "        model_inputs['labels'][idx][end_idx+1:] = -100\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(NLTP_Dataset(train_path), batch_size=batch_size, shuffle=True, collate_fn=preprocess)\n",
    "test_dataloader = DataLoader(NLTP_Dataset(test_path), batch_size=batch_size, shuffle=False, collate_fn=preprocess)\n",
    "valid_dataloader = DataLoader(NLTP_Dataset(valid_path), batch_size=batch_size, shuffle=False, collate_fn=preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d48c1c8fec4c8cb72493537b6d522e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddd8a24806940bebec69ba18594744e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 100.00\n",
      "\n",
      "saving valid results\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c38a265bd645a7a60bf1a4bc859a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 100.00\n",
      "\n",
      "saving valid results\n",
      "Epoch 3/5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd73de44fafa4343baa12e66ef72df0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 100.00\n",
      "\n",
      "saving valid results\n",
      "Epoch 4/5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552cb6de6fd54f77a7ecdb0485ebafe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 100.00\n",
      "\n",
      "saving valid results\n",
      "Epoch 5/5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cc8db2cee84359af1b59de49052eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 100.00\n",
      "\n",
      "saving valid results\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def test_loop(dataloader, model, epoch):\n",
    "    sources, preds, labels =[], [], []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_target_length,\n",
    "            ).cpu().numpy()\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "        \n",
    "        decoded_sources = tokenizer.batch_decode(\n",
    "            batch_data[\"input_ids\"].cpu().numpy(), \n",
    "            skip_special_tokens=True, \n",
    "            use_source_tokenizer=True\n",
    "        )\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        sources += [source.strip() for source in decoded_sources]\n",
    "        preds += [pred.strip() for pred in decoded_preds]\n",
    "        labels += [[label.strip()] for label in decoded_labels]\n",
    "    bleu_score = bleu.corpus_score(preds, labels).score\n",
    "    print(f\"BLEU: {bleu_score:>0.2f}\\n\")\n",
    "\n",
    "    results = []\n",
    "    print(\"saving valid results\")\n",
    "    for source, pred, label in zip(sources, preds, labels):\n",
    "        results.append({\n",
    "            \"sentence\": source, \n",
    "            \"prediction\": pred, \n",
    "            \"translation\": label[0]\n",
    "        })\n",
    "    f = open(f'/home/xinming/Text2ESQ/out_files/easy_nltp_weights/easy_nltp_valid_pred_{epoch+1}.json', 'wt')\n",
    "    json.dump(results, f)\n",
    "    f.close()   \n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "best_bleu = 0.\n",
    "for t in tqdm(range(epoch_num)):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_bleu = test_loop(valid_dataloader, model, t)\n",
    "    if valid_bleu > best_bleu:\n",
    "        best_bleu = valid_bleu\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            f'/home/xinming/Text2ESQ/out_files/easy_nltp_weights/NLTP_epoch_{t+1}_valid_bleu_{valid_bleu:0.2f}_model_weights.bin'\n",
    "        )\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbb87cc1daa49e2b2981a6f25a57299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BLEU: 86.94\n",
      "\n",
      "saving predicted results...\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/xinming/Text2ESQ/out_files/easy_nltp_weights/NLTP_epoch_1_valid_bleu_100.00_model_weights.bin'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sources, preds, labels = [], [], []\n",
    "    for batch_data in tqdm(test_dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            batch_data[\"input_ids\"],\n",
    "            attention_mask=batch_data[\"attention_mask\"],\n",
    "            max_length=max_target_length,\n",
    "        ).cpu().numpy()\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_sources = tokenizer.batch_decode(\n",
    "            batch_data[\"input_ids\"].cpu().numpy(), \n",
    "            skip_special_tokens=True, \n",
    "            use_source_tokenizer=True\n",
    "        )\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        sources += [source.strip() for source in decoded_sources]\n",
    "        preds += [pred.strip() for pred in decoded_preds]\n",
    "        labels += [[label.strip()] for label in decoded_labels]\n",
    "    bleu_score = bleu.corpus_score(preds, labels).score\n",
    "    print(f\"Test BLEU: {bleu_score:>0.2f}\\n\")\n",
    "    results = []\n",
    "    print('saving predicted results...')\n",
    "    for source, pred, label in zip(sources, preds, labels):\n",
    "        results.append({\n",
    "            \"sentence\": source, \n",
    "            \"prediction\": pred, \n",
    "            \"translation\": label[0]\n",
    "        })\n",
    "    f = open('/home/xinming/Text2ESQ/out_files/easy_nltp_weights/nltp_m2m_test_pred.json', 'wt')\n",
    "    json.dump(results, f)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1_fmeasure': tensor(0.9208),\n",
      " 'rouge1_precision': tensor(0.9285),\n",
      " 'rouge1_recall': tensor(0.9158),\n",
      " 'rouge2_fmeasure': tensor(0.8724),\n",
      " 'rouge2_precision': tensor(0.8796),\n",
      " 'rouge2_recall': tensor(0.8676),\n",
      " 'rougeL_fmeasure': tensor(0.9184),\n",
      " 'rougeL_precision': tensor(0.9260),\n",
      " 'rougeL_recall': tensor(0.9134),\n",
      " 'rougeLsum_fmeasure': tensor(0.9185),\n",
      " 'rougeLsum_precision': tensor(0.9261),\n",
      " 'rougeLsum_recall': tensor(0.9135)}\n"
     ]
    }
   ],
   "source": [
    "# Valid rouge\n",
    "file_path = '/home/xinming/Text2ESQ/out_files/easy_nltp_weights/easy_nltp_valid_pred_5.json'\n",
    "f = open(file_path, 'r')\n",
    "data = json.load(f)\n",
    "\n",
    "preds = [x['prediction'] for x in data]\n",
    "target = [x['translation'] for x in data]\n",
    "\n",
    "pprint(rouge_score(preds, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1_fmeasure': tensor(0.9028),\n",
      " 'rouge1_precision': tensor(0.9129),\n",
      " 'rouge1_recall': tensor(0.8969),\n",
      " 'rouge2_fmeasure': tensor(0.8428),\n",
      " 'rouge2_precision': tensor(0.8518),\n",
      " 'rouge2_recall': tensor(0.8374),\n",
      " 'rougeL_fmeasure': tensor(0.8985),\n",
      " 'rougeL_precision': tensor(0.9084),\n",
      " 'rougeL_recall': tensor(0.8924),\n",
      " 'rougeLsum_fmeasure': tensor(0.8986),\n",
      " 'rougeLsum_precision': tensor(0.9085),\n",
      " 'rougeLsum_recall': tensor(0.8925)}\n"
     ]
    }
   ],
   "source": [
    "# Test rouge\n",
    "file_path = '/home/xinming/Text2ESQ/out_files/easy_nltp_weights/nltp_m2m_test_pred.json'\n",
    "f = open(file_path, 'r')\n",
    "data = json.load(f)\n",
    "\n",
    "preds = [x['prediction'] for x in data]\n",
    "target = [x['translation'] for x in data]\n",
    "\n",
    "pprint(rouge_score(preds, target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e6de408c761b7a5a99b261145d5ad97b0baf5c7e97b102b04e36d3a3d50be32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
